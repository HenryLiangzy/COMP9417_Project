{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "#import altair as alt\n",
    "# need to 'pip install vega' before using renderer\n",
    "#alt.renderers.enable(\"notebook\")\n",
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve,StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import scipy\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "# test for Selecting The Best Number Of Components For TSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "%matplotlib inline\n",
    "#fix random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable vega --py --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_number    0\n",
      "article_words     0\n",
      "topic             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_words</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open,absent,cent,cent,cent,stock,inflow,rate,k...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>morn,stead,end,end,day,day,day,patch,patch,pat...</td>\n",
       "      <td>MONEY MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>socc,socc,world,world,recent,law,fifa,fifa,fif...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>open,forint,forint,forint,forint,cent,cent,ste...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>morn,complet,weekend,minut,minut,minut,arrow,d...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_number                                      article_words  \\\n",
       "0               1  open,absent,cent,cent,cent,stock,inflow,rate,k...   \n",
       "1               2  morn,stead,end,end,day,day,day,patch,patch,pat...   \n",
       "2               3  socc,socc,world,world,recent,law,fifa,fifa,fif...   \n",
       "3               4  open,forint,forint,forint,forint,cent,cent,ste...   \n",
       "4               5  morn,complet,weekend,minut,minut,minut,arrow,d...   \n",
       "\n",
       "           topic  \n",
       "0  FOREX MARKETS  \n",
       "1  MONEY MARKETS  \n",
       "2         SPORTS  \n",
       "3  FOREX MARKETS  \n",
       "4     IRRELEVANT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_FILE = \"../training.csv\"\n",
    "TEST_FILE = \"../test.csv\"\n",
    "df = pd.read_csv(TRAINING_FILE)\n",
    "print(df.isnull().sum())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is old version, which executes the **train_test_split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #new_df = df[df.topic!='IRRELEVANT'] # We remove rows that are \"IRRELEVANT\"\n",
    "# new_df = df\n",
    "# data_x = new_df.article_words\n",
    "# data_y = new_df.topic\n",
    "# train_x,dev_x,train_y,dev_y = train_test_split(data_x,data_y,test_size = 0.1,shuffle=False)\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(train_y)\n",
    "# encode_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "# en_train_y = le.transform(train_y)\n",
    "# en_dev_y = le.transform(dev_y)\n",
    "# topics = list(set(df['topic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is new version, which does not execute the **train_test_split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "train_x = new_df.article_words.apply(lambda x: x.replace('_', ''))\n",
    "train_y = new_df.topic\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y)\n",
    "encode_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "en_train_y = le.transform(train_y)\n",
    "topics = list(set(df['topic']))\n",
    "TOPIC_COUNT = len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alt.data_transformers.disable_max_rows()\n",
    "# bars = alt.Chart(train_y.to_frame()).mark_bar(size=50).encode(\n",
    "# x=alt.X(\"topic\"),\n",
    "# y=alt.Y(\"count():Q\", axis=alt.Axis(title='Number of articles')),\n",
    "# tooltip=[alt.Tooltip('count()', title='Number of articles'), 'topic'],\n",
    "# color='topic'\n",
    "\n",
    "# )\n",
    "\n",
    "# text = bars.mark_text(\n",
    "# align='center',\n",
    "# baseline='bottom',\n",
    "# ).encode(\n",
    "# text='count()'\n",
    "# )\n",
    "\n",
    "# (bars + text).properties(\n",
    "#     height=300, \n",
    "#     width=700,\n",
    "#     title = \"Number of articles in each category\",\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Training Text to TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is old version, which executes the **train_test_split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# train_vectors = vectorizer.fit_transform(train_x)\n",
    "# dev_vectors = vectorizer.transform(dev_x)\n",
    "# print(train_vectors.shape,dev_vectors.shape)\n",
    "# print(train_vectors.nnz/float(train_vectors.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is new version without **train_test_split()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Is Applied Here Now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Best **n-component** in TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52074, 9495)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "vectorizer.fit(train_x)\n",
    "train_vectors = vectorizer.transform(train_x)\n",
    "smo_x,smo_y = smote.fit_sample(train_vectors,en_train_y)\n",
    "train_sparse = csr_matrix(smo_x)\n",
    "print(train_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=train_sparse.shape[1]-1)\n",
    "train_tsvd = tsvd.fit(smo_x)\n",
    "tsvd_var_ratios = tsvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_components(var_ratio,goal_var:float)-> int:\n",
    "    total_variance = 0.0\n",
    "    n_components=0\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance +=explained_variance\n",
    "        n_components+=1\n",
    "        if (total_variance>=goal_var):\n",
    "            break\n",
    "    return (n_components)\n",
    "best_n_components = select_n_components(tsvd_var_ratios,0.95)\n",
    "print(\"The best n_component number is\",best_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=best_n_components)\n",
    "train_tsvd = tsvd.fit(smo_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: this model already exits...\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Models/train_tsvd.joblib\"\n",
    "if not os.path.exists(file_name):\n",
    "    # Export the model (TFIDF+logistic regressor)\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        joblib.dump(train_tsvd, file, compress=True)\n",
    "else:\n",
    "    print(\"Warn: this model already exits...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since SMOTE cannot be passed to pipe, we inverse transform the smo_x to text first\n",
    "new_train_x = vectorizer.inverse_transform(smo_x)\n",
    "new_train_x = pd.Series([','.join(item) for item in new_train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_N_COMPONENTS = 2261\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "# # standard pipeline interface\n",
    "# estimators = [\n",
    "#               (\"tfidf\", TfidfVectorizer()),\n",
    "#               (\"tsvd\",TruncatedSVD(random_state=1,n_components = best_n_components)),\n",
    "#               (\"model\",MultinomialNB())\n",
    "#               ]\n",
    "\n",
    "# pipe = Pipeline(estimators)\n",
    "\n",
    "# # Notice here parameters need to be specified to which step in the pipeline they belong to\n",
    "# param_grid = {\n",
    "#                \"tfidf__min_df\" : [i for i in range(2,10)],\n",
    "#                 #\"model__alpha\":[0.001,0.01,0.1,1],\n",
    "#                 #\"model__fit_prior\": [True,False],\n",
    "#                 # since SMOTE makes the distribution uniform, we want to test the assumption of \n",
    "#                 # normal distribution below\n",
    "#                 #\"model__class_prior\":[None,[1/len(topics) for i in range(len(topics))]]\n",
    "#             }\n",
    "# pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# grid = GridSearchCV(pipe, param_grid, cv=kfold, n_jobs=-1)\n",
    "\n",
    "# # through in original tevxt samples\n",
    "# grid.fit(new_train_x, smo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 9s, sys: 13.2 s, total: 5min 23s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=BEST_N_COMPONENTS)\n",
    "tsvd.fit(smo_x)\n",
    "train_tsvd = tsvd.transform(smo_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Models/train_tsvd.joblib\"\n",
    "# dirname = os.path.dirname(file_name)\n",
    "# if not os.path.dirname(dirname):\n",
    "#     os.removedirs(dirname)\n",
    "#     os.makedirs(dirname)\n",
    "with open(file_name, \"wb\") as file:\n",
    "        dump(train_tsvd, file, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Models/train_tsvd.joblib\"\n",
    "train_tsvd = load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE to Solve Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, by plotting each topic's frequency, it could be seen that the distribution of topics is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering in the data set, the topic 'MONEY MARKET' occupies the majority, which might, indirectly, lead to biased prediction to itself, we need to adjust each topic's proportion in the training data set. In this project, SMOTE (Synthetic Minority Over-sampling TEchnique) is used to solve the imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=1)\n",
    "# smo_x,smo_y = smote.fit_sample(train_vectors,en_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Warning: The following block runs for a long time, don't run it if not necessary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueManagerThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/import/cage/2/z5277884/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 747, in _queue_management_worker\n",
      "    recursive_terminate(p)\n",
      "  File \"/import/cage/2/z5277884/.local/lib/python3.7/site-packages/joblib/externals/loky/backend/utils.py\", line 26, in recursive_terminate\n",
      "    _recursive_terminate_with_psutil(process)\n",
      "  File \"/import/cage/2/z5277884/.local/lib/python3.7/site-packages/joblib/externals/loky/backend/utils.py\", line 33, in _recursive_terminate_with_psutil\n",
      "    children = psutil.Process(process.pid).children(recursive=True)\n",
      "  File \"/usr/lib/python3/dist-packages/psutil/__init__.py\", line 384, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/psutil/__init__.py\", line 996, in children\n",
      "    ppid_map = _ppid_map()\n",
      "  File \"/usr/lib/python3/dist-packages/psutil/_pslinux.py\", line 1492, in ppid_map\n",
      "    with open_binary(\"%s/%s/stat\" % (procfs_path, pid)) as f:\n",
      "  File \"/usr/lib/python3/dist-packages/psutil/_common.py\", line 586, in open_binary\n",
      "    return open(fname, \"rb\", **kwargs)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/proc/1/stat'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ecb10271db37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfit_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tsvd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmo_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best parameters are {0}, with score {1:4}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = [0.005*n for n in range(1,201)]\n",
    "#alpha = [0.01*n for n in range(1,101)]\n",
    "\n",
    "fit_prior = [True,False]\n",
    "# After using SMOTE to improve the imbalance, we can assume the distribution is uniform distribution\n",
    "prior = [1/len(topics) for i in range(len(topics))]\n",
    "class_prior = [None,prior]\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "param_grid = dict(alpha=alpha,fit_prior=fit_prior,class_prior=class_prior)\n",
    "grid_search = GridSearchCV(MultinomialNB(),param_grid,scoring='neg_log_loss',n_jobs=-1,cv=kfold)\n",
    "grid_result = grid_search.fit(train_tsvd,smo_y)\n",
    "print(\"The best parameters are {0}, with score {1:4}\".format(grid_result.best_params_,grid_result.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(en_dev_y,pred_y,model_name,topic=None):\n",
    "    f1 = f1_score(en_dev_y,pred_y,average='macro')\n",
    "    accuracy = accuracy_score(en_dev_y,pred_y)\n",
    "    recall = recall_score(en_dev_y,pred_y,average='macro')\n",
    "    if(topic==None):\n",
    "        print(\"F1 score for \",model_name,\" model is \",f1)\n",
    "        print(\"Accuracy score for \",model_name,\" model is \",accuracy)\n",
    "        print(\"Recall score for \",model_name,\" model is \",recall,\"\\n\")\n",
    "    else:\n",
    "        return ([topic,{'accuracy':accuracy,'f1':f1,'recall':recall}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for  MultinomialNB  model is  0.6243282286371143\n",
      "Accuracy score for  MultinomialNB  model is  0.751578947368421\n",
      "Recall score for  MultinomialNB  model is  0.6454504196521257 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit data\n",
    "clf = MultinomialNB(alpha=0.003)\n",
    "clf.fit(smo_x,smo_y)\n",
    "pred_y = clf.predict(dev_vectors)\n",
    "get_scores(en_dev_y,pred_y,'MultinomialNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3414969164647438\n",
      "0.9591665676605537\n"
     ]
    }
   ],
   "source": [
    "proba_y = clf.predict_proba(dev_vectors)\n",
    "print(min([max(lst) for lst in proba_y]))\n",
    "print(roc_auc_score(en_dev_y,proba_y,multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999990479\n"
     ]
    }
   ],
   "source": [
    "irr_data = df[df.topic=='IRRELEVANT']\n",
    "irr_x = irr_data.article_words\n",
    "irr_y = irr_data.topic\n",
    "en_irr_y = le.fit_transform(irr_y)\n",
    "irr_vectors = vectorizer.transform(irr_x)\n",
    "irr_proba_y = clf.predict_proba(irr_vectors)\n",
    "print(max([max(lst) for lst in irr_proba_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_number    0\n",
      "article_words     0\n",
      "topic             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_words</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9501</td>\n",
       "      <td>world,complet,pharmaceut,tianjin,tianjin,chin,...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9502</td>\n",
       "      <td>copy,sunday,weekend,ec,friday,eu,includ,limit,...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9503</td>\n",
       "      <td>heavy,heavy,gabriel,morn,morn,equit,cent,cent,...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9504</td>\n",
       "      <td>research,jess,hit,anticip,comput,comput,comput...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9505</td>\n",
       "      <td>provid,provid,luxembourg,court,court,case,opin...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_number                                      article_words  \\\n",
       "0            9501  world,complet,pharmaceut,tianjin,tianjin,chin,...   \n",
       "1            9502  copy,sunday,weekend,ec,friday,eu,includ,limit,...   \n",
       "2            9503  heavy,heavy,gabriel,morn,morn,equit,cent,cent,...   \n",
       "3            9504  research,jess,hit,anticip,comput,comput,comput...   \n",
       "4            9505  provid,provid,luxembourg,court,court,case,opin...   \n",
       "\n",
       "           topic  \n",
       "0     IRRELEVANT  \n",
       "1     IRRELEVANT  \n",
       "2  FOREX MARKETS  \n",
       "3     IRRELEVANT  \n",
       "4     IRRELEVANT  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "print(df_test.isnull().sum())\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y= df_test.topic\n",
    "le.fit(train_y)\n",
    "en_test_y = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores for Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_for_topics(df,topics,model,le):\n",
    "    scores = []\n",
    "    for topic in topics:\n",
    "        topic_scores(df,topic,model,le,scores)\n",
    "    scores.sort(reverse=True,key=lambda x:x[1]['accuracy'])\n",
    "    for item in scores:\n",
    "        print(item)\n",
    "\n",
    "def topic_scores(df,topic,model,le,scores):\n",
    "    new_df = df[df.topic==topic]\n",
    "    test_x = new_df.article_words\n",
    "    test_y = new_df.topic\n",
    "    test_vectors = vectorizer.transform(test_x)\n",
    "    le.fit(train_y)\n",
    "    en_test_y = le.transform(test_y)\n",
    "    prediction = model.predict(test_vectors)\n",
    "    scores.append(get_scores(en_test_y,prediction,type(model).__name__,topic))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SCIENCE AND TECHNOLOGY', 'ARTS CULTURE ENTERTAINMENT',\n",
       "       'IRRELEVANT', 'HEALTH'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([8,0,6,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPORTS', {'accuracy': 1.0, 'f1': 1.0, 'recall': 1.0}]\n",
      "['HEALTH', {'accuracy': 0.8571428571428571, 'f1': 0.4615384615384615, 'recall': 0.42857142857142855}]\n",
      "['IRRELEVANT', {'accuracy': 0.7819548872180451, 'f1': 0.09751523675574308, 'recall': 0.08688387635756056}]\n",
      "['FOREX MARKETS', {'accuracy': 0.6875, 'f1': 0.2716049382716049, 'recall': 0.22916666666666666}]\n",
      "['MONEY MARKETS', {'accuracy': 0.5652173913043478, 'f1': 0.24074074074074073, 'recall': 0.18840579710144925}]\n",
      "['DEFENCE', {'accuracy': 0.5384615384615384, 'f1': 0.35000000000000003, 'recall': 0.2692307692307692}]\n",
      "['DOMESTIC MARKETS', {'accuracy': 0.5, 'f1': 0.3333333333333333, 'recall': 0.25}]\n",
      "['BIOGRAPHIES PERSONALITIES PEOPLE', {'accuracy': 0.4, 'f1': 0.14285714285714288, 'recall': 0.1}]\n",
      "['ARTS CULTURE ENTERTAINMENT', {'accuracy': 0.3333333333333333, 'f1': 0.16666666666666666, 'recall': 0.1111111111111111}]\n",
      "['SHARE LISTINGS', {'accuracy': 0.14285714285714285, 'f1': 0.125, 'recall': 0.07142857142857142}]\n",
      "['SCIENCE AND TECHNOLOGY', {'accuracy': 0.0, 'f1': 0.0, 'recall': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "scores_for_topics(df_test,topics,clf,le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
