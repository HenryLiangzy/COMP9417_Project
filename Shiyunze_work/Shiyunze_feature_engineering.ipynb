{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "---\n",
    "1. **read in raw datasets**\n",
    "2. **Label coding**: topics to integers\n",
    "3. **Text Cleaning**: cleaning of special characters\n",
    "4. **Text representation**: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_words</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open,absent,cent,cent,cent,stock,inflow,rate,k...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>morn,stead,end,end,day,day,day,patch,patch,pat...</td>\n",
       "      <td>MONEY MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>socc,socc,world,world,recent,law,fifa,fifa,fif...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>open,forint,forint,forint,forint,cent,cent,ste...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>morn,complet,weekend,minut,minut,minut,arrow,d...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_number                                      article_words  \\\n",
       "0               1  open,absent,cent,cent,cent,stock,inflow,rate,k...   \n",
       "1               2  morn,stead,end,end,day,day,day,patch,patch,pat...   \n",
       "2               3  socc,socc,world,world,recent,law,fifa,fifa,fif...   \n",
       "3               4  open,forint,forint,forint,forint,cent,cent,ste...   \n",
       "4               5  morn,complet,weekend,minut,minut,minut,arrow,d...   \n",
       "\n",
       "           topic  \n",
       "0  FOREX MARKETS  \n",
       "1  MONEY MARKETS  \n",
       "2         SPORTS  \n",
       "3  FOREX MARKETS  \n",
       "4     IRRELEVANT  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9500, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"training.csv\")\n",
    "df_train.head()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: label\n",
      "{'ARTS CULTURE ENTERTAINMENT': 0,\n",
      " 'BIOGRAPHIES PERSONALITIES PEOPLE': 1,\n",
      " 'DEFENCE': 2,\n",
      " 'DOMESTIC MARKETS': 3,\n",
      " 'FOREX MARKETS': 4,\n",
      " 'HEALTH': 5,\n",
      " 'IRRELEVANT': 6,\n",
      " 'MONEY MARKETS': 7,\n",
      " 'SCIENCE AND TECHNOLOGY': 8,\n",
      " 'SHARE LISTINGS': 9,\n",
      " 'SPORTS': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_words</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>open,absent,cent,cent,cent,stock,inflow,rate,k...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>morn,stead,end,end,day,day,day,patch,patch,pat...</td>\n",
       "      <td>MONEY MARKETS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>socc,socc,world,world,recent,law,fifa,fifa,fif...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>open,forint,forint,forint,forint,cent,cent,ste...</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>morn,complet,weekend,minut,minut,minut,arrow,d...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_number                                      article_words  \\\n",
       "0               1  open,absent,cent,cent,cent,stock,inflow,rate,k...   \n",
       "1               2  morn,stead,end,end,day,day,day,patch,patch,pat...   \n",
       "2               3  socc,socc,world,world,recent,law,fifa,fifa,fif...   \n",
       "3               4  open,forint,forint,forint,forint,cent,cent,ste...   \n",
       "4               5  morn,complet,weekend,minut,minut,minut,arrow,d...   \n",
       "\n",
       "           topic  label  \n",
       "0  FOREX MARKETS      4  \n",
       "1  MONEY MARKETS      7  \n",
       "2         SPORTS     10  \n",
       "3  FOREX MARKETS      4  \n",
       "4     IRRELEVANT      6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a encoder on the training topics\n",
    "label_train = df_train.topic\n",
    "\n",
    "# encode labels (alphabetic order) to integers 0-10\n",
    "label_encoder = LabelEncoder().fit(label_train)\n",
    "y_train = label_encoder.transform(label_train)\n",
    "\n",
    "topic_to_label = {k: v for (k, v) in zip(\\\n",
    "                                         label_encoder.classes_, \n",
    "                                         label_encoder.transform(label_encoder.classes_)\n",
    "                                        )}\n",
    "print(\"topic: label\")\n",
    "pprint(topic_to_label)\n",
    "# Insert the encoded column in to original dataframe\n",
    "df_train[\"label\"] = y_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove \"_\" in each document\n",
    "text_train = df_train.article_words.apply(lambda x: x.replace('_', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text Representing\n",
    "## 4.1 Bulid Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35817\n",
      "\n",
      "The first 40 features:\n",
      "['a1', 'a1b1', 'a2', 'a3', 'a300', 'a300b4', 'a320', 'a330', 'a340', 'a4', 'a5', 'a6', 'a7', 'a78', 'a7e', 'aa', 'aa1', 'aa2', 'aa3', 'aaa', 'aacount', 'aad', 'aadj', 'aag', 'aah', 'aahp', 'aair', 'aalborg', 'aalst', 'aalton', 'aaltonaa', 'aama', 'aamir', 'aamodt', 'aandewiel', 'aap', 'aapc', 'aapt', 'aaqib', 'aaquib']\n",
      "\n",
      "Features 20010 to 20050:\n",
      "['mercad', 'mercado', 'mercantil', 'mercaton', 'merced', 'mercen', 'merch', 'merchandis', 'merci', 'mercilon', 'merck', 'merckx', 'mercosur', 'mercur', 'mercurio', 'mercy', 'merdior', 'mere', 'merebank', 'meret', 'merg', 'merial', 'merid', 'meridian', 'meridor', 'merin', 'meris', 'merisel', 'merit', 'meriwether']\n",
      "\n",
      "Every 1000th feature:\n",
      "['a1', 'altamir', 'atkin', 'beke', 'boulton', 'cardiothorac', 'clarin', 'credent', 'desant', 'dump', 'est', 'flap', 'genev', 'guotai', 'hockeyroo', 'inflexibl', 'joke', 'koek', 'leppan', 'mainstay', 'mentheor', 'movie', 'nitchipourenk', 'ota', 'person', 'prevar', 'realloc', 'rollin', 'schlesing', 'silty', 'stanchart', 'tadash', 'toma', 'undon', 'virog', 'woodhead']\n"
     ]
    }
   ],
   "source": [
    "#fit the CountVectorizer to text_train\n",
    "count_vector = CountVectorizer().fit(text_train)\n",
    "features = count_vector.get_feature_names()\n",
    "\n",
    "print(f\"Vocabulary size: {len(count_vector.vocabulary_)}\")\n",
    "print(f\"\\nThe first 40 features:\\n{features[:40]}\")\n",
    "print(\"\\nFeatures 20010 to 20050:\\n{}\".format(features[20010:20040]))\n",
    "print(\"\\nEvery 1000th feature:\\n{}\".format(features[::1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer().fit(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/export_list.joblib exported\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "files_to_export = {\\\n",
    "                   \"Data/label_encoder.joblib\": label_encoder,  # label encoder fitted to df_train.topic\n",
    "                   \"Data/df_train.joblib\": df_train,            # add transformed label column to raw dataset\n",
    "                   \"Data/text_train.joblib\": text_train,        # cleaned df_train.article_words\n",
    "                   \"Data/y_train.joblib\": y_train,              # final training label\n",
    "                   \"Data/count_vector.joblib\": count_vector,    # CountVectorizer fitted to text_train\n",
    "                   \"Data/tf_idf.joblib\": tf_idf                 # tf-idf vectorizer fitted to text_train\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: Data/label_encoder.joblib already exits...\n",
      "Warn: Data/df_train.joblib already exits...\n",
      "Warn: Data/text_train.joblib already exits...\n",
      "Warn: Data/y_train.joblib already exits...\n",
      "Warn: Data/count_vector.joblib already exits...\n",
      "Warn: Data/tf_idf.joblib already exits...\n"
     ]
    }
   ],
   "source": [
    "# df_train\n",
    "for file_name, obj in files_to_export.items():\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            joblib.dump(obj, file)\n",
    "            print(f\"{file_name} exported\")\n",
    "    else:\n",
    "        print(f\"Warn: {file_name} already exits...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
