{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Brad_work.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi9OWu2Z1C_u",
        "colab_type": "code",
        "outputId": "8d04d1d1-fb9f-485e-9202-402976dc8df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugpph71mzGOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bbcc024-7b4e-466f-f2da-c64dbc3aaaff"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import scipy\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from keras.regularizers import l2\n",
        "np.random.seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcyZrkjZ0Xgc",
        "colab_type": "code",
        "outputId": "2ff907b9-0a30-46b6-c282-9d9737b38960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EgG0iW91LWB",
        "colab_type": "code",
        "outputId": "29ea47b6-5ae6-4998-a2d4-1471210f1d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Brad_work.ipynb\t\t    hw2\n",
            "'Colab Notebooks'\t\t    Individual_Component.zip\n",
            " COMP9021_Lec1_wyn_note.ipynb\t    test.csv\n",
            "'Copy of new.drawio'\t\t    training.csv\n",
            "'Copy of Untitled Diagram.drawio'   Untitled0.ipynb\n",
            "'CSESoc FYG 2019.gdoc'\t\t   'Untitled Diagram (1).drawio'\n",
            "'CSESoc FYG 2019.pdf'\t\t   'Untitled Diagram.drawio'\n",
            " Group_Component.zip\t\t   'Untitled document.gdoc'\n",
            " GSOE9820.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1YYkguzGOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"/content/drive/My Drive/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JLxpZ8nzGOz",
        "colab_type": "code",
        "outputId": "e0ce5441-481b-4809-bf43-24f86eb17fd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "test_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_number</th>\n",
              "      <th>article_words</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9501</td>\n",
              "      <td>world,complet,pharmaceut,tianjin,tianjin,chin,...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9502</td>\n",
              "      <td>copy,sunday,weekend,ec,friday,eu,includ,limit,...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9503</td>\n",
              "      <td>heavy,heavy,gabriel,morn,morn,equit,cent,cent,...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9504</td>\n",
              "      <td>research,jess,hit,anticip,comput,comput,comput...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9505</td>\n",
              "      <td>provid,provid,luxembourg,court,court,case,opin...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>9996</td>\n",
              "      <td>symantec,soon,interfac,provid,provid,comput,co...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>9997</td>\n",
              "      <td>hit,hit,hit,hit,hit,hit,hit,hit,hit,beat,beat,...</td>\n",
              "      <td>SPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>9998</td>\n",
              "      <td>cent,cent,cent,cent,match,declin,act,rate,rate...</td>\n",
              "      <td>MONEY MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9999</td>\n",
              "      <td>cnmv,cnmv,stock,count,count,week,group,friday,...</td>\n",
              "      <td>SHARE LISTINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>10000</td>\n",
              "      <td>matthey,matthey,metal,hit,morn,widen,widen,cen...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     article_number  ...           topic\n",
              "0              9501  ...      IRRELEVANT\n",
              "1              9502  ...      IRRELEVANT\n",
              "2              9503  ...   FOREX MARKETS\n",
              "3              9504  ...      IRRELEVANT\n",
              "4              9505  ...      IRRELEVANT\n",
              "..              ...  ...             ...\n",
              "495            9996  ...      IRRELEVANT\n",
              "496            9997  ...          SPORTS\n",
              "497            9998  ...   MONEY MARKETS\n",
              "498            9999  ...  SHARE LISTINGS\n",
              "499           10000  ...      IRRELEVANT\n",
              "\n",
              "[500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLKxwIUnzGO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/My Drive/training.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpHwm4PSzGO8",
        "colab_type": "code",
        "outputId": "7ea180ae-88e5-4849-8db2-f0ffb3d7a9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_number</th>\n",
              "      <th>article_words</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>open,absent,cent,cent,cent,stock,inflow,rate,k...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>morn,stead,end,end,day,day,day,patch,patch,pat...</td>\n",
              "      <td>MONEY MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>socc,socc,world,world,recent,law,fifa,fifa,fif...</td>\n",
              "      <td>SPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>open,forint,forint,forint,forint,cent,cent,ste...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>morn,complet,weekend,minut,minut,minut,arrow,d...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9495</th>\n",
              "      <td>9496</td>\n",
              "      <td>cloud,provid,hope,centur,erupt,rule,recent,sou...</td>\n",
              "      <td>DEFENCE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9496</th>\n",
              "      <td>9497</td>\n",
              "      <td>stock,stock,stock,declin,access,week,worry,blo...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9497</th>\n",
              "      <td>9498</td>\n",
              "      <td>rate,million,million,belarus,dollar,dollar,nov...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9498</th>\n",
              "      <td>9499</td>\n",
              "      <td>flow,bullet,bullet,bullet,bullet,bullet,bullet...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9499</th>\n",
              "      <td>9500</td>\n",
              "      <td>helsingin,mechan,follow,sanomat,limit,market,r...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      article_number  ...          topic\n",
              "0                  1  ...  FOREX MARKETS\n",
              "1                  2  ...  MONEY MARKETS\n",
              "2                  3  ...         SPORTS\n",
              "3                  4  ...  FOREX MARKETS\n",
              "4                  5  ...     IRRELEVANT\n",
              "...              ...  ...            ...\n",
              "9495            9496  ...        DEFENCE\n",
              "9496            9497  ...     IRRELEVANT\n",
              "9497            9498  ...  FOREX MARKETS\n",
              "9498            9499  ...     IRRELEVANT\n",
              "9499            9500  ...  FOREX MARKETS\n",
              "\n",
              "[9500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo8E-5bdzGPA",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "*base on the work of Raymond*\n",
        "\n",
        "Use  ``` CountVectorizer ``` and ``` TfidfVectorizer ``` to extract features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3gI12KnzGPB",
        "colab_type": "code",
        "outputId": "5dcb8dfb-890d-476e-d9da-e1e24b89be70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "train_x = train_df.article_words\n",
        "train_y = train_df.topic\n",
        "test_x = test_df.article_words\n",
        "test_y = test_df.topic\n",
        "\n",
        "en_train_y = preprocessing.LabelEncoder().fit_transform(train_y)\n",
        "en_test_y = preprocessing.LabelEncoder().fit_transform(test_y)\n",
        "categories_list=list(set(train_df['topic']))\n",
        "print(categories_list)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ARTS CULTURE ENTERTAINMENT', 'MONEY MARKETS', 'IRRELEVANT', 'BIOGRAPHIES PERSONALITIES PEOPLE', 'SPORTS', 'SHARE LISTINGS', 'HEALTH', 'DEFENCE', 'DOMESTIC MARKETS', 'SCIENCE AND TECHNOLOGY', 'FOREX MARKETS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWdZDiR01ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    sp = tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "    sp = tf.sparse.reorder(sp)\n",
        "    return sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqv5egmS3jdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get Count vectors\n",
        "vectorizer = CountVectorizer().fit(train_x)\n",
        "train_count_csr = vectorizer.transform(train_x)\n",
        "test_count_csr = vectorizer.transform(test_x)\n",
        "\n",
        "# change count vectors from scipy.sparse.csr.csr_matrix to tf.sparse.SparseTensor\n",
        "train_count_st = convert_sparse_matrix_to_sparse_tensor(train_count_csr)\n",
        "test_count_st = convert_sparse_matrix_to_sparse_tensor(test_count_csr)\n",
        "\n",
        "# change count vectors from tf.sparse.SparseTensor to tf.Tensor\n",
        "train_count_dense = tf.sparse.to_dense(train_count_st)\n",
        "test_count_dense = tf.sparse.to_dense(test_count_st)\n",
        "\n",
        "# get Tfid vectors\n",
        "vectorizer = TfidfVectorizer().fit(train_x)\n",
        "train_tfid_csr = vectorizer.transform(train_x)\n",
        "test_tfid_csr = vectorizer.transform(test_x)\n",
        "\n",
        "# change Tfid vectors from scipy.sparse.csr.csr_matrix to tf.sparse.SparseTensor\n",
        "train_tfid_st = convert_sparse_matrix_to_sparse_tensor(train_tfid_csr)\n",
        "test_tfid_st = convert_sparse_matrix_to_sparse_tensor(test_tfid_csr)\n",
        "\n",
        "# change Tfid vecotors from tf.sparse.SparseTensor to tf.Tensor\n",
        "train_tfid_dense = tf.sparse.to_dense(train_tfid_st)\n",
        "test_tfid_dense = tf.sparse.to_dense(test_tfid_st)\n",
        "\n",
        "# # get Tfid vector vocab size\n",
        "# vocab_size_tfid = train_vectors.shape[1]\n",
        "# print(train_vectors.shape,test_vectors.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA5qFkMs-tN3",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing data and preserve order\n",
        "\n",
        "From ```Tokenizer``` to ```pad_sequences```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDD_RNq7nDUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_num = 500\n",
        "tokenizer = Tokenizer(num_words=word_num)\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "train_token = tokenizer.texts_to_sequences(train_x)\n",
        "test_token = tokenizer.texts_to_sequences(test_x)\n",
        "train_pad = pad_sequences(train_token)\n",
        "word_length = train_pad.shape[1]\n",
        "test_pad = pad_sequences(test_token, maxlen=word_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A1ACfZCDG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cate_accuracies(matrix, categories):\n",
        "    for i_row in range(len(matrix)):\n",
        "        acc = matrix[i_row][i_row]/sum(matrix[i_row])\n",
        "        print(f\"The accuracy for {categories[i_row]} is {acc}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IdUSkzBzGPI",
        "colab_type": "text"
      },
      "source": [
        "# Training Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUSLsyXa9NR",
        "colab_type": "text"
      },
      "source": [
        "# Best Training model so far\n",
        "Already tried:\n",
        "* other linear layers combinations \n",
        "    * with/without dropout layers\n",
        "    * with/without weight decay\n",
        "* tokenize + embedding + LSTM\n",
        "    * extremely slow and inaccurate, not sure if it is because of underfitting or context information not preserved since it is too slow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RqGpj6udY__",
        "colab_type": "code",
        "outputId": "d9b9df17-d4b8-45a6-ea67-513bb3a87ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def network():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(11, activation='relu'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=network, epochs=50, batch_size=20, verbose=0)\n",
        "\n",
        "start_time = time.time()\n",
        "estimator.fit(train_count_st, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "train_pred = estimator.predict(train_count_st)\n",
        "print(\"Training confusion matrix\")\n",
        "print(metrics.confusion_matrix(train_y, train_pred, categories_list))\n",
        "\n",
        "train_f1 = metrics.f1_score(train_y, train_pred, average='macro')\n",
        "print(f\"Training f1 score is {train_f1}.\")\n",
        "\n",
        "train_acc = metrics.accuracy_score(train_y, train_pred)\n",
        "print(f\"Training accuracy score is {train_acc}.\")\n",
        "\n",
        "train_recall = metrics.recall_score(train_y, train_pred, average=\"macro\")\n",
        "print(f\"Training recall score is {train_recall}\")\n",
        "\n",
        "test_pred = estimator.predict(test_count_st)\n",
        "print(\"Test confusion matrix\")\n",
        "\n",
        "confusion = metrics.confusion_matrix(test_y, test_pred, categories_list)\n",
        "print(confusion)\n",
        "\n",
        "test_f1 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(f\"Test f1 score is {test_f1}.\")\n",
        "\n",
        "test_acc = metrics.accuracy_score(test_y, test_pred)\n",
        "print(f\"Test accuracy score is {test_acc}.\")\n",
        "\n",
        "test_recall = metrics.recall_score(test_y, test_pred, average=\"macro\")\n",
        "print(f\"Test recall score is {test_recall}\")\n",
        "\n",
        "test_report = metrics.classification_report(test_y, test_pred)\n",
        "print(test_report)\n",
        "\n",
        "cate_accuracies(confusion, categories_list)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 55s\n",
            "Training confusion matrix\n",
            "[[   3    0   66   39    6    0    0    0    0    3    0]\n",
            " [   0 1593    9    0    0    0    0    0    0    0   71]\n",
            " [   0   50 4655    0   18    0    0    2    0    0    9]\n",
            " [   2    0    9  154    2    0    0    0    0    0    0]\n",
            " [   0    0    1    1 1100    0    0    0    0    0    0]\n",
            " [   0    0  216    0    2    0    0    0    0    0    0]\n",
            " [   3    0  143    9    0    0    0    2    0   26    0]\n",
            " [   0    0    2    0    0    0    0  256    0    0    0]\n",
            " [   0    0    5    0    0    0    0    0  128    0    0]\n",
            " [   2    0    5    0    1    0    0    1    0   61    0]\n",
            " [   0   64    4    0    0    0    0    0    0    0  777]]\n",
            "Training f1 score is 0.6724143189983453.\n",
            "Training accuracy score is 0.9186315789473685.\n",
            "Training recall score is 0.693371366089414\n",
            "Test confusion matrix\n",
            "[[  0   0   3   0   0   0   0   0   0   0   0]\n",
            " [  0  43   6   0   0   0   0   0   0   0  20]\n",
            " [  1  16 240   1   3   0   0   2   1   0   2]\n",
            " [  0   0   8   7   0   0   0   0   0   0   0]\n",
            " [  0   0   2   0  58   0   0   0   0   0   0]\n",
            " [  0   0   7   0   0   0   0   0   0   0   0]\n",
            " [  0   0  11   0   0   0   0   0   0   3   0]\n",
            " [  0   0   4   0   0   0   0   9   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0   0]\n",
            " [  0   0   2   0   0   0   0   0   0   1   0]\n",
            " [  0  19   8   0   0   0   0   0   0   0  21]]\n",
            "Test f1 score is 0.4828563204069302.\n",
            "Test accuracy score is 0.762.\n",
            "Test recall score is 0.4929016730790186\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "      ARTS CULTURE ENTERTAINMENT       0.00      0.00      0.00         3\n",
            "BIOGRAPHIES PERSONALITIES PEOPLE       0.88      0.47      0.61        15\n",
            "                         DEFENCE       0.82      0.69      0.75        13\n",
            "                DOMESTIC MARKETS       0.67      1.00      0.80         2\n",
            "                   FOREX MARKETS       0.49      0.44      0.46        48\n",
            "                          HEALTH       0.00      0.00      0.00        14\n",
            "                      IRRELEVANT       0.82      0.90      0.86       266\n",
            "                   MONEY MARKETS       0.55      0.62      0.59        69\n",
            "          SCIENCE AND TECHNOLOGY       0.25      0.33      0.29         3\n",
            "                  SHARE LISTINGS       0.00      0.00      0.00         7\n",
            "                          SPORTS       0.95      0.97      0.96        60\n",
            "\n",
            "                        accuracy                           0.76       500\n",
            "                       macro avg       0.49      0.49      0.48       500\n",
            "                    weighted avg       0.73      0.76      0.74       500\n",
            "\n",
            "The accuracy for ARTS CULTURE ENTERTAINMENT is 0.0.\n",
            "The accuracy for MONEY MARKETS is 0.6231884057971014.\n",
            "The accuracy for IRRELEVANT is 0.9022556390977443.\n",
            "The accuracy for BIOGRAPHIES PERSONALITIES PEOPLE is 0.4666666666666667.\n",
            "The accuracy for SPORTS is 0.9666666666666667.\n",
            "The accuracy for SHARE LISTINGS is 0.0.\n",
            "The accuracy for HEALTH is 0.0.\n",
            "The accuracy for DEFENCE is 0.6923076923076923.\n",
            "The accuracy for DOMESTIC MARKETS is 1.0.\n",
            "The accuracy for SCIENCE AND TECHNOLOGY is 0.3333333333333333.\n",
            "The accuracy for FOREX MARKETS is 0.4375.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skVK4uBXVyaS",
        "colab_type": "code",
        "outputId": "4ef7b274-9c23-4f77-c10a-65ebf6f4293b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def network():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu',\n",
        "              kernel_regularizer=l2(0.01),\n",
        "              bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu',\n",
        "              kernel_regularizer=l2(0.01),\n",
        "              bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(11, activation='relu',\n",
        "              kernel_regularizer=l2(0.01),\n",
        "              bias_regularizer=l2(0.01)))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "estimator = KerasClassifier(build_fn=network, epochs=10, batch_size=20, verbose=0)\n",
        "\n",
        "start_time = time.time()\n",
        "estimator.fit(train_count_st, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "train_pred = estimator.predict(train_count_st)\n",
        "print(\"Training confusion matrix\")\n",
        "print(metrics.confusion_matrix(train_y, train_pred, categories_list))\n",
        "\n",
        "train_f1 = metrics.f1_score(train_y, train_pred, average='macro')\n",
        "print(f\"Training f1 score is {train_f1}.\")\n",
        "\n",
        "train_acc = metrics.accuracy_score(train_y, train_pred)\n",
        "print(f\"Training accuracy score is {train_acc}.\")\n",
        "\n",
        "train_recall = metrics.recall_score(train_y, train_pred, average=\"macro\")\n",
        "print(f\"Training recall score is {train_recall}\")\n",
        "\n",
        "test_pred = estimator.predict(test_count_st)\n",
        "print(\"Test confusion matrix\")\n",
        "\n",
        "confusion = metrics.confusion_matrix(test_y, test_pred, categories_list)\n",
        "print(confusion)\n",
        "\n",
        "test_f1 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(f\"Test f1 score is {test_f1}.\")\n",
        "\n",
        "test_acc = metrics.accuracy_score(test_y, test_pred)\n",
        "print(f\"Test accuracy score is {test_acc}.\")\n",
        "\n",
        "test_recall = metrics.recall_score(test_y, test_pred, average=\"macro\")\n",
        "print(f\"Test recall score is {test_recall}\")\n",
        "\n",
        "test_report = metrics.classification_report(test_y, test_pred)\n",
        "print(test_report)\n",
        "\n",
        "cate_accuracies(confusion, categories_list)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 14s\n",
            "Training confusion matrix\n",
            "[[   4    0   43   69    1    0    0    0    0    0    0]\n",
            " [   0 1594   78    0    0    0    0    0    0    0    1]\n",
            " [   1  279 4331   14   48   16   15   22    8    0    0]\n",
            " [   0    0   67   93    3    0    2    2    0    0    0]\n",
            " [   0    1    9    4 1088    0    0    0    0    0    0]\n",
            " [   0    0  103    0    1  114    0    0    0    0    0]\n",
            " [   0    0   82    2    1    0   97    1    0    0    0]\n",
            " [   0    0   72    0    0    0    1  185    0    0    0]\n",
            " [   0    0   91    0    0    0    0    0   42    0    0]\n",
            " [   0    1   23    0    1    0   20    0    0   25    0]\n",
            " [   0  800   43    0    0    0    0    0    0    0    2]]\n",
            "Training f1 score is 0.5674625596731576.\n",
            "Training accuracy score is 0.7973684210526316.\n",
            "Training recall score is 0.5355785957701877\n",
            "Test confusion matrix\n",
            "[[  0   0   2   1   0   0   0   0   0   0   0]\n",
            " [  0  63   6   0   0   0   0   0   0   0   0]\n",
            " [  0  21 238   1   3   2   1   0   0   0   0]\n",
            " [  0   0   9   6   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  60   0   0   0   0   0   0]\n",
            " [  0   0   3   0   0   4   0   0   0   0   0]\n",
            " [  0   0   7   0   0   0   7   0   0   0   0]\n",
            " [  0   0   5   0   0   0   0   8   0   0   0]\n",
            " [  0   0   2   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   1   0   0   1   0   0   0   0]\n",
            " [  0  46   2   0   0   0   0   0   0   0   0]]\n",
            "Test f1 score is 0.4522375218545218.\n",
            "Test accuracy score is 0.772.\n",
            "Test recall score is 0.4449630461072109\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "      ARTS CULTURE ENTERTAINMENT       0.00      0.00      0.00         3\n",
            "BIOGRAPHIES PERSONALITIES PEOPLE       0.67      0.40      0.50        15\n",
            "                         DEFENCE       1.00      0.62      0.76        13\n",
            "                DOMESTIC MARKETS       0.00      0.00      0.00         2\n",
            "                   FOREX MARKETS       0.00      0.00      0.00        48\n",
            "                          HEALTH       0.78      0.50      0.61        14\n",
            "                      IRRELEVANT       0.87      0.89      0.88       266\n",
            "                   MONEY MARKETS       0.48      0.91      0.63        69\n",
            "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         3\n",
            "                  SHARE LISTINGS       0.67      0.57      0.62         7\n",
            "                          SPORTS       0.95      1.00      0.98        60\n",
            "\n",
            "                        accuracy                           0.77       500\n",
            "                       macro avg       0.49      0.44      0.45       500\n",
            "                    weighted avg       0.72      0.77      0.73       500\n",
            "\n",
            "The accuracy for ARTS CULTURE ENTERTAINMENT is 0.0.\n",
            "The accuracy for MONEY MARKETS is 0.9130434782608695.\n",
            "The accuracy for IRRELEVANT is 0.8947368421052632.\n",
            "The accuracy for BIOGRAPHIES PERSONALITIES PEOPLE is 0.4.\n",
            "The accuracy for SPORTS is 1.0.\n",
            "The accuracy for SHARE LISTINGS is 0.5714285714285714.\n",
            "The accuracy for HEALTH is 0.5.\n",
            "The accuracy for DEFENCE is 0.6153846153846154.\n",
            "The accuracy for DOMESTIC MARKETS is 0.0.\n",
            "The accuracy for SCIENCE AND TECHNOLOGY is 0.0.\n",
            "The accuracy for FOREX MARKETS is 0.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtZRPPhCt458",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}