{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Brad_work.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi9OWu2Z1C_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67b5c146-297e-4cfa-9a06-9fcfd291f315"
      },
      "source": [
        "!ls /content/drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugpph71mzGOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcyZrkjZ0Xgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2881b0c1-1eb5-4c7e-bd8c-447c4284cd40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EgG0iW91LWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8764a916-2a88-47d7-d8e2-6007c1c8f86b"
      },
      "source": [
        "!ls /content/drive/My\\ Drive"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Brad_work.ipynb\t\t    hw2\n",
            "'Colab Notebooks'\t\t    Individual_Component.zip\n",
            " COMP9021_Lec1_wyn_note.ipynb\t    test.csv\n",
            "'Copy of new.drawio'\t\t    training.csv\n",
            "'Copy of Untitled Diagram.drawio'   Untitled0.ipynb\n",
            "'CSESoc FYG 2019.gdoc'\t\t   'Untitled Diagram (1).drawio'\n",
            "'CSESoc FYG 2019.pdf'\t\t   'Untitled Diagram.drawio'\n",
            " Group_Component.zip\t\t   'Untitled document.gdoc'\n",
            " GSOE9820.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1YYkguzGOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"/content/drive/My Drive/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JLxpZ8nzGOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "02fe615e-e66d-4c44-85ed-5590bf815645"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_number</th>\n",
              "      <th>article_words</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9501</td>\n",
              "      <td>world,complet,pharmaceut,tianjin,tianjin,chin,...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9502</td>\n",
              "      <td>copy,sunday,weekend,ec,friday,eu,includ,limit,...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9503</td>\n",
              "      <td>heavy,heavy,gabriel,morn,morn,equit,cent,cent,...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9504</td>\n",
              "      <td>research,jess,hit,anticip,comput,comput,comput...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9505</td>\n",
              "      <td>provid,provid,luxembourg,court,court,case,opin...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>9996</td>\n",
              "      <td>symantec,soon,interfac,provid,provid,comput,co...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>9997</td>\n",
              "      <td>hit,hit,hit,hit,hit,hit,hit,hit,hit,beat,beat,...</td>\n",
              "      <td>SPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>9998</td>\n",
              "      <td>cent,cent,cent,cent,match,declin,act,rate,rate...</td>\n",
              "      <td>MONEY MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9999</td>\n",
              "      <td>cnmv,cnmv,stock,count,count,week,group,friday,...</td>\n",
              "      <td>SHARE LISTINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>10000</td>\n",
              "      <td>matthey,matthey,metal,hit,morn,widen,widen,cen...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     article_number  ...           topic\n",
              "0              9501  ...      IRRELEVANT\n",
              "1              9502  ...      IRRELEVANT\n",
              "2              9503  ...   FOREX MARKETS\n",
              "3              9504  ...      IRRELEVANT\n",
              "4              9505  ...      IRRELEVANT\n",
              "..              ...  ...             ...\n",
              "495            9996  ...      IRRELEVANT\n",
              "496            9997  ...          SPORTS\n",
              "497            9998  ...   MONEY MARKETS\n",
              "498            9999  ...  SHARE LISTINGS\n",
              "499           10000  ...      IRRELEVANT\n",
              "\n",
              "[500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLKxwIUnzGO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/My Drive/training.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpHwm4PSzGO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "92898f3b-6a7c-4541-aef0-1321bfd2ffc1"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_number</th>\n",
              "      <th>article_words</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>open,absent,cent,cent,cent,stock,inflow,rate,k...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>morn,stead,end,end,day,day,day,patch,patch,pat...</td>\n",
              "      <td>MONEY MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>socc,socc,world,world,recent,law,fifa,fifa,fif...</td>\n",
              "      <td>SPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>open,forint,forint,forint,forint,cent,cent,ste...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>morn,complet,weekend,minut,minut,minut,arrow,d...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9495</th>\n",
              "      <td>9496</td>\n",
              "      <td>cloud,provid,hope,centur,erupt,rule,recent,sou...</td>\n",
              "      <td>DEFENCE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9496</th>\n",
              "      <td>9497</td>\n",
              "      <td>stock,stock,stock,declin,access,week,worry,blo...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9497</th>\n",
              "      <td>9498</td>\n",
              "      <td>rate,million,million,belarus,dollar,dollar,nov...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9498</th>\n",
              "      <td>9499</td>\n",
              "      <td>flow,bullet,bullet,bullet,bullet,bullet,bullet...</td>\n",
              "      <td>IRRELEVANT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9499</th>\n",
              "      <td>9500</td>\n",
              "      <td>helsingin,mechan,follow,sanomat,limit,market,r...</td>\n",
              "      <td>FOREX MARKETS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9500 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      article_number  ...          topic\n",
              "0                  1  ...  FOREX MARKETS\n",
              "1                  2  ...  MONEY MARKETS\n",
              "2                  3  ...         SPORTS\n",
              "3                  4  ...  FOREX MARKETS\n",
              "4                  5  ...     IRRELEVANT\n",
              "...              ...  ...            ...\n",
              "9495            9496  ...        DEFENCE\n",
              "9496            9497  ...     IRRELEVANT\n",
              "9497            9498  ...  FOREX MARKETS\n",
              "9498            9499  ...     IRRELEVANT\n",
              "9499            9500  ...  FOREX MARKETS\n",
              "\n",
              "[9500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo8E-5bdzGPA",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "*base on the work of Raymond*\n",
        "\n",
        "Use  ``` CountVectorizer ``` and ``` TfidfVectorizer ``` to extract features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3gI12KnzGPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f2865c73-961f-48a5-8134-38663b1bb2ff"
      },
      "source": [
        "train_x = train_df.article_words\n",
        "train_y = train_df.topic\n",
        "test_x = test_df.article_words\n",
        "test_y = test_df.topic\n",
        "\n",
        "en_train_y = preprocessing.LabelEncoder().fit_transform(train_y)\n",
        "en_test_y = preprocessing.LabelEncoder().fit_transform(test_y)\n",
        "categories=list(set(train_df['topic']))\n",
        "print(categories)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BIOGRAPHIES PERSONALITIES PEOPLE', 'SHARE LISTINGS', 'IRRELEVANT', 'FOREX MARKETS', 'HEALTH', 'ARTS CULTURE ENTERTAINMENT', 'DOMESTIC MARKETS', 'MONEY MARKETS', 'SPORTS', 'SCIENCE AND TECHNOLOGY', 'DEFENCE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWdZDiR01ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    sp = tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "    sp = tf.sparse.reorder(sp)\n",
        "    return sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqv5egmS3jdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get Count vectors\n",
        "vectorizer = CountVectorizer().fit(train_x)\n",
        "train_count_csr = vectorizer.transform(train_x)\n",
        "test_count_csr = vectorizer.transform(test_x)\n",
        "\n",
        "# change count vectors from scipy.sparse.csr.csr_matrix to tf.sparse.SparseTensor\n",
        "train_count_st = convert_sparse_matrix_to_sparse_tensor(train_count_csr)\n",
        "test_count_st = convert_sparse_matrix_to_sparse_tensor(test_count_csr)\n",
        "\n",
        "# change count vectors from tf.sparse.SparseTensor to tf.Tensor\n",
        "train_count_dense = tf.sparse.to_dense(train_count_st)\n",
        "test_count_dense = tf.sparse.to_dense(test_count_st)\n",
        "\n",
        "# get Tfid vectors\n",
        "vectorizer = TfidfVectorizer().fit(train_x)\n",
        "train_tfid_csr = vectorizer.transform(train_x)\n",
        "test_tfid_csr = vectorizer.transform(test_x)\n",
        "\n",
        "# change Tfid vectors from scipy.sparse.csr.csr_matrix to tf.sparse.SparseTensor\n",
        "train_tfid_st = convert_sparse_matrix_to_sparse_tensor(train_tfid_csr)\n",
        "test_tfid_st = convert_sparse_matrix_to_sparse_tensor(test_tfid_csr)\n",
        "\n",
        "# change Tfid vecotors from tf.sparse.SparseTensor to tf.Tensor\n",
        "train_tfid_dense = tf.sparse.to_dense(train_tfid_st)\n",
        "test_tfid_dense = tf.sparse.to_dense(test_tfid_st)\n",
        "\n",
        "# # get Tfid vector vocab size\n",
        "# vocab_size_tfid = train_vectors.shape[1]\n",
        "# print(train_vectors.shape,test_vectors.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IdUSkzBzGPI",
        "colab_type": "text"
      },
      "source": [
        "# Training Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afrijP7SzGPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "def network():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8192, input_dim=35822, activation='relu'))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(11, activation='relu'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znBp-q6JzGPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = KerasClassifier(build_fn=network, epochs=20, batch_size=5, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0LaC9TzGPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "df4300d7-4b4f-45e4-adb2-1d04e359ae05"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "estimator.fit(train_tfid_st, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "test_pred = estimator.predict(test_tfid_st)\n",
        "metrics.confusion_matrix(test_y, test_pred, categories)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 894s\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  13,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  48,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  14,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 266,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  69,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   7,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  60,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "889zIfe26Xwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "81be9c81-2630-42a8-dfc3-cd9c44a7d82a"
      },
      "source": [
        "print(metrics.accuracy_score(test_y, test_pred))\n",
        "print(metrics.precision_score(test_y, test_pred, average=\"micro\"))\n",
        "print(metrics.recall_score(test_y, test_pred, average=\"micro\"))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.532\n",
            "0.532\n",
            "0.532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQX9ytPuAOHg",
        "colab_type": "text"
      },
      "source": [
        "# Training Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpJTM9klAY6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 10\n",
        "\n",
        "def network():\n",
        "    global embedding_dim, vocab_size_tfid\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size_tfid,\n",
        "                        embedding_dim,\n",
        "                        input_length=vocab_size_tfid))\n",
        "    # (batch, vocab_size) -> (batch * vocab_size * embedding_dim)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    # (batch, vocab_size)\n",
        "    model.add(Dense(11, activation='relu'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0geQHRKyKp5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "0c610ffb-ba8c-43b3-e7ac-b26008d323a5"
      },
      "source": [
        "import time\n",
        "\n",
        "# get Tfid vector vocab size\n",
        "vocab_size_tfid = train_tfid_dense.shape[1]\n",
        "\n",
        "estimator = KerasClassifier(build_fn=network, epochs=20, batch_size=5, verbose=0)\n",
        "start_time = time.time()\n",
        "estimator.fit(train_tfid_dense, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "test_pred = estimator.predict(test_tfid_dense)\n",
        "metrics.confusion_matrix(test_y, test_pred, categories)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 1738s\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  13,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  48,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  14,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 266,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  69,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  60,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm-KEp2eTVjI",
        "colab_type": "text"
      },
      "source": [
        "# Training Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCJJDGnFE4Za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "60b93260-4c54-45b9-907c-d633ad094d07"
      },
      "source": [
        "embedding_dim = 10\n",
        "\n",
        "def network():\n",
        "    global embedding_dim, vocab_size\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size,\n",
        "                        embedding_dim,\n",
        "                        input_length=vocab_size))\n",
        "    # (batch, vocab_size) -> (batch * vocab_size * embedding_dim)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    # (batch, vocab_size)\n",
        "    model.add(Dense(11, activation='relu'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "import time\n",
        "\n",
        "# get count vector vocab size\n",
        "vocab_size = train_count_dense.shape[1]\n",
        "\n",
        "estimator = KerasClassifier(build_fn=network, epochs=20, batch_size=5, verbose=0)\n",
        "start_time = time.time()\n",
        "estimator.fit(train_count_dense, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "test_pred = estimator.predict(test_count_dense)\n",
        "metrics.confusion_matrix(test_y, test_pred, categories)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 537s\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
              "       [ 10,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0],\n",
              "       [ 11,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0],\n",
              "       [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,  47,   0,   0,   0],\n",
              "       [ 11,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0],\n",
              "       [129,   0,   0,   0,   0,   0,   0, 137,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  69,   0,   0,   0],\n",
              "       [  3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   6,   0,   0,   0],\n",
              "       [ 15,   0,   0,   0,   0,   0,   0,  45,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN9_sFgbQPiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "36655317-fb13-487b-f7ab-58a3fb78731f"
      },
      "source": [
        "def network():\n",
        "    global vocab_size\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8192, input_dim=vocab_size, activation='relu'))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(11, activation='relu'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=network, epochs=20, batch_size=5, verbose=0)\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "# get count vector vocab size\n",
        "vocab_size = train_count_dense.shape[1]\n",
        "\n",
        "start_time = time.time()\n",
        "estimator.fit(train_count_st, train_y)\n",
        "print(f\"Training time {time.time()-start_time:.0f}s\")\n",
        "test_pred = estimator.predict(test_count_st)\n",
        "print(metrics.confusion_matrix(test_y, test_pred, categories))\n",
        "\n",
        "print(metrics.accuracy_score(test_y, test_pred))\n",
        "print(metrics.precision_score(test_y, test_pred, average=\"micro\"))\n",
        "print(metrics.recall_score(test_y, test_pred, average=\"micro\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time 887s\n",
            "[[  0   0  14   0   0   0   0   0   1   0   0]\n",
            " [  0   0   7   0   0   0   0   0   0   0   0]\n",
            " [  0   0 239   3   0   0   0  21   3   0   0]\n",
            " [  0   0   4  16   0   1   0  27   0   0   0]\n",
            " [  0   0  14   0   0   0   0   0   0   0   0]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0]\n",
            " [  0   0   2   0   0   0   0   0   0   0   0]\n",
            " [  0   0   3  16   0   0   0  50   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0  59   0   0]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0]\n",
            " [  0   0  13   0   0   0   0   0   0   0   0]]\n",
            "0.728\n",
            "0.728\n",
            "0.728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Xpr26Zg6zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}