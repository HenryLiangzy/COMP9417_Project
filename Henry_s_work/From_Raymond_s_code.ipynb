{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Raymond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "#import altair as alt\n",
    "# need to 'pip install vega' before using renderer\n",
    "#alt.renderers.enable(\"notebook\")\n",
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.utils import shuffle\n",
    "import scipy\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "# test for Selecting The Best Number Of Components For TSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from varname import varname\n",
    "%matplotlib inline\n",
    "#fix random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE = \"../keyword.csv\"\n",
    "TEST_FILE = \"../key_word_test.csv\"\n",
    "df_train = pd.read_csv(TRAINING_FILE)\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "print(df_train.isnull().sum())\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out training sets with different size of keywords in the training set\n",
    "df_train_10 = pd.DataFrame(df_train,columns=['key_word_10','topic']).rename(columns={'key_word_10':'key_word'})\n",
    "df_train_10.name = 'df_train_10'\n",
    "df_train_20 = pd.DataFrame(df_train,columns=['key_word_20','topic']).rename(columns={'key_word_20':'key_word'})\n",
    "df_train_20.name = 'df_train_20'\n",
    "df_train_50 = pd.DataFrame(df_train,columns=['key_word_50','topic']).rename(columns={'key_word_50':'key_word'})\n",
    "df_train_50.name = 'df_train_50'\n",
    "df_train_100 = pd.DataFrame(df_train,columns=['key_word_100','topic']).rename(columns={'key_word_100':'key_word'})\n",
    "df_train_100.name = 'df_train_100'\n",
    "df_train_full = pd.DataFrame(df_train,columns=['article_words','topic']).rename(columns={'article_words':'key_word'})\n",
    "df_train_full.name = 'df_train_full'\n",
    "df_train_all = [df_train_10,df_train_20,df_train_50,df_train_100,df_train_full]\n",
    "\n",
    "# Separate out training sets with different size of keywords in the test set\n",
    "df_test_10 = pd.DataFrame(df_test,columns=['key_word_10','topic']).rename(columns={'key_word_10':'key_word'})\n",
    "df_test_10.name = 'df_test_10'\n",
    "df_test_20 = pd.DataFrame(df_test,columns=['key_word_20','topic']).rename(columns={'key_word_20':'key_word'})\n",
    "df_test_20.name = 'df_test_20'\n",
    "df_test_50 = pd.DataFrame(df_test,columns=['key_word_50','topic']).rename(columns={'key_word_50':'key_word'})\n",
    "df_test_50.name = 'df_test_50'\n",
    "df_test_100 = pd.DataFrame(df_test,columns=['key_word_100','topic']).rename(columns={'key_word_100':'key_word'})\n",
    "df_test_100.name = 'df_test_100'\n",
    "df_test_full = pd.DataFrame(df_test,columns=['article_words','topic']).rename(columns={'article_words':'key_word'})\n",
    "df_test_full.name = 'df_test_full'\n",
    "df_test_all = [df_test_10,df_test_20,df_test_50,df_test_100,df_test_full]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_10.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     return ([x for x in globals() if globals()[x] is df][0])\n",
    "\n",
    "def get_scores(en_train_y,pred_y,model_name,topic=None):\n",
    "    f1 = f1_score(en_train_y,pred_y,average='macro')\n",
    "    accuracy = accuracy_score(en_train_y,pred_y)\n",
    "    recall = recall_score(en_train_y,pred_y,average='macro')\n",
    "    if(topic==None):\n",
    "        print(\"F1 score for \",model_name,\" model is \",f1)\n",
    "        print(\"Accuracy score for \",model_name,\" model is \",accuracy)\n",
    "        print(\"Recall score for \",model_name,\" model is \",recall,\"\\n\")\n",
    "    else:\n",
    "        return ([topic,{'accuracy':accuracy,'f1':f1,'recall':recall}])\n",
    "def save_variable(variable,filename):\n",
    "    file_name = \"Models/\"+filename+\".joblib\"\n",
    "    if not os.path.exists(file_name):\n",
    "    # Export the model (TFIDF+logistic regressor)\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            dump(variable, file, compress=True)\n",
    "    else:\n",
    "        print(\"Warn: this model already exits...\")\n",
    "        \n",
    "def retrieve_variable(filename):\n",
    "    file_name = \"Models/\"+filename+\".joblib\"\n",
    "    return(load(file_name))\n",
    "\n",
    "def scores_for_topics(df,topics,model,le):\n",
    "    scores = []\n",
    "    for topic in topics:\n",
    "        topic_scores(df,topic,model,le,scores)\n",
    "    scores.sort(reverse=True,key=lambda x:x[1]['accuracy'])\n",
    "    for item in scores:\n",
    "        print(item)\n",
    "\n",
    "def topic_scores(df,topic,model,le,scores):\n",
    "    filtered_df = df[df.topic==topic]\n",
    "    test_x = filtered_df.key_word.apply(lambda x: x.replace('_', ''))\n",
    "    test_y = filtered_df.topic\n",
    "    #le.fit(train_y)\n",
    "    en_test_y = le.transform(test_y)\n",
    "    prediction = model.predict(test_x)\n",
    "    scores.append(get_scores(en_test_y,prediction,type(model).__name__,topic))\n",
    "    \n",
    "def scores_for_topics(df,topics,model,le):\n",
    "    scores = []\n",
    "    for topic in topics:\n",
    "        topic_scores(df,topic,model,le,scores)\n",
    "    scores.sort(reverse=True,key=lambda x:x[1]['accuracy'])\n",
    "    for item in scores:\n",
    "        print(item)\n",
    "\n",
    "def topic_scores(df,topic,model,le,scores):\n",
    "    filtered_df = df[df.topic==topic]\n",
    "    test_x = filtered_df.key_word.apply(lambda x: x.replace('_', ''))\n",
    "    test_y = filtered_df.topic\n",
    "    en_test_y = le.transform(test_y)\n",
    "    prediction = model.predict(test_x)\n",
    "    scores.append(get_scores(en_test_y,prediction,type(model).__name__,topic))\n",
    "    \n",
    "def grid_search(vectorizer,model,train_x,train_y,topics):\n",
    "    kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "    estimators = [\n",
    "                (\"vectorizer\",vectorizer),\n",
    "                (\"model\",model)\n",
    "                  ]\n",
    "    pipe = Pipeline(estimators)\n",
    "\n",
    "    param_grid = {\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [i for i in range(10, 100)],\n",
    "        'min_samples_split': [i for i in range(2, 10)],\n",
    "        'min_samples_leaf': [i for i in range(1, 10)],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=kfold, n_jobs=-1)\n",
    "    grid_result=grid_search.fit(train_x, train_y)\n",
    "    return (grid_result.best_estimator_,grid_result.best_score_)\n",
    "    \n",
    "def get_model(df_train):\n",
    "    # get train_x and train_y\n",
    "    new_df = df_train\n",
    "    new_df = new_df.dropna()\n",
    "    train_x = new_df.key_word.apply(lambda x: x.replace('_', ''))\n",
    "    train_y = new_df.topic\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_y)\n",
    "    encode_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    en_train_y = le.transform(train_y)\n",
    "    topics = list(set(new_df['topic']))\n",
    "    # Using SMOTE to solve imbalance\n",
    "    smote = SMOTE(random_state=1)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(train_x)\n",
    "    train_vectors = vectorizer.transform(train_x)\n",
    "    smo_x,smo_y = smote.fit_sample(train_vectors,en_train_y)\n",
    "    new_train_x = vectorizer.inverse_transform(smo_x)\n",
    "    new_train_x = pd.Series([','.join(item) for item in new_train_x])\n",
    "    # Start grid search\n",
    "    count_clf_NB,count_clf_accuracy = grid_search(CountVectorizer(),DecisionTreeClassifier(),\\\n",
    "                                                  new_train_x,smo_y,topics)\n",
    "    tfidf_clf_NB,tfidf_clf_accuracy = grid_search(TfidfVectorizer(norm=None),DecisionTreeClassifier(),\\\n",
    "                                                  new_train_x,smo_y,topics)\n",
    "    if(count_clf_accuracy>=tfidf_clf_accuracy):\n",
    "        print(f'*************************************************************')\n",
    "        print(f'Now the training set is {df_train.name}, and the model chosen is count_clf_NB')\n",
    "        print(f'The accuracy is {count_clf_accuracy}')\n",
    "        return (count_clf_NB,le,encode_mapping)\n",
    "    else:\n",
    "        print(f'*************************************************************')\n",
    "        print(f'Now the training set is {df_train.name}, and the model chosen is tfidf_clf_NB')\n",
    "        print(f'The accuracy is {tfidf_clf_accuracy}')\n",
    "        return (tfidf_clf_NB,le,encode_mapping)\n",
    "    \n",
    "def test_model(df_test,model,le,encode_mapping):\n",
    "    test_x = df_test.key_word\n",
    "    test_y = df_test.topic\n",
    "    topics = list(set(df_test['topic']))\n",
    "    en_test_y = le.transform(test_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    get_scores(en_test_y,y_pred,type(model).__name__)\n",
    "    print(encode_mapping)\n",
    "    print(f\"Classification Report:\\n{classification_report(en_test_y, y_pred)}\")\n",
    "    print(\"The scores for each topic is:\")\n",
    "    scores_for_topics(df_test,topics,model,le)\n",
    "    conf_matrix = confusion_matrix(en_test_y, y_pred)\n",
    "    print(conf_matrix)\n",
    "    fig1 = plt.figure(figsize=(13,6))\n",
    "    sns.heatmap(conf_matrix,\n",
    "    #             square=True,\n",
    "                annot=True, # show numbers in each cell\n",
    "                fmt='d', # set number format to integer in each cell\n",
    "                yticklabels=le.classes_,\n",
    "                xticklabels=model.classes_,\n",
    "                cmap=\"Blues\",\n",
    "    #             linecolor=\"k\",\n",
    "                linewidths=.1,\n",
    "               )\n",
    "    plt.title(\n",
    "              f\"Confusion Matrix on Test Set | \" \n",
    "              f\"Classifier: {'+'.join([step for step in clf_NB.named_steps.keys()])}\", \n",
    "              fontsize=14)\n",
    "    plt.xlabel(\"Actual: False positives for y != x\", fontsize=12)\n",
    "    plt.ylabel(\"Prediction: False negatives for x != y\", fontsize=12)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for train_df in df_train_all:\n",
    "    clf_NB,le,encode_mapping = get_model(train_df)\n",
    "    for test_df in df_test_all:\n",
    "        if (test_df.isnull().values.any()):\n",
    "            continue\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print(f'Now, the train_df is {train_df.name}, the test_df is {test_df.name}')\n",
    "        test_model(test_df,clf_NB,le,encode_mapping)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit440a9b05b92d4257b31359ad5d640545",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}